{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder for anomaly detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    " \n",
    "import os \n",
    "import random \n",
    "from IPython import display \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for building the model and training\n",
    "BATCH_SIZE = 1\n",
    "LATENT_DIM = 128\n",
    "IMAGE_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_slices_paths(image_dir):\n",
    "    ''' returns a list of paths to the image files'''\n",
    "    image_file_list = os.listdir(image_dir)\n",
    "    image_paths = [os.path.join(image_dir, fname) for fname in image_file_list]\n",
    "\n",
    "    return image_paths \n",
    "\n",
    "def map_image(image_filename): \n",
    "    ''' preprocess the images'''\n",
    "    img_raw = tf.io.read_file(image_filename)\n",
    "    image = tf.image.decode_jpeg(img_raw) # depends on the type of images\n",
    "\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = image/255.0\n",
    "    image = tf.reshape(image, shape=(IMAGE_SIZE, IMAGE_SIZE,3,))\n",
    "\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None: \n",
    "            img = cv2.resize(img, (64,64))\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "folder_path = \"/OneDrive/Documents/STUDY/AutoEncoder/training_data/\"\n",
    "\n",
    "image_data = load_images_from_folder(folder_path)\n",
    "\n",
    "image_data = image_data.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fabric(dataset, size=4):\n",
    "    ''' Takes a sample from a dataset batch and plots it in a grid. '''\n",
    "    dataset = dataset.unbatch().take(size)\n",
    "    n_cols = 2\n",
    "    n_rows = size//n_cols+1\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    i=0\n",
    "    for image in dataset:\n",
    "        i+=1 \n",
    "        disp_image = np.reshape(image, (64,64,3))\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(disp_image)\n",
    "\n",
    "def display_one_row(dis_images, offset, shape=(64,64)):\n",
    "    ''' Display a row of images. '''\n",
    "    for i, img in enumerate(dis_images):\n",
    "        plt.subplot(2,2,offset+i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        image = np.reshape(img, shape)\n",
    "        plt.imshow(img)\n",
    "\n",
    "def display_results(dis_input_images, dis_predicted):\n",
    "    ''' Display input and predicted images. '''\n",
    "    plt.figure(figsize=(5,5))\n",
    "    display_one_row(dis_input_images, 0, shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    display_one_row(dis_predicted, 20, shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_images(images, num_images=4, figsize=(10, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(num_images):\n",
    "        ax = plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')  # Adjust the colormap based on image color format\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming image_data is already loaded and preprocessed\n",
    "# Display the first 5 images from image_data\n",
    "display_images(image_data, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unbatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\Documents\\STUDY\\AutoEncoder\\VAE.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m display_fabric(image_data, size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;32md:\\OneDrive\\Documents\\STUDY\\AutoEncoder\\VAE.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdisplay_fabric\u001b[39m(dataset, size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m''' Takes a sample from a dataset batch and plots it in a grid. '''\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49munbatch()\u001b[39m.\u001b[39mtake(size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     n_cols \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     n_rows \u001b[39m=\u001b[39m size\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mn_cols\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unbatch'"
     ]
    }
   ],
   "source": [
    "display_fabric(image_data, size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Class\n",
    "\n",
    "This layer provide the Gaussian noise input along with the mean ($\\mu $) and standard deviation ($\\sigma$) of the encoder's output, according to the following equation:\n",
    "**$$z = \\mu + e^{0.5\\sigma} * \\epsilon $$**\n",
    "($\\epsilon$ = random sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        ''' Generates a random sample and combines with the encoder output\n",
    "        Args:\n",
    "        inputs - output tensor from the encoder \n",
    "        Returns: \n",
    "        'inputs' tensors combined with a random sample\n",
    "        '''\n",
    "        mu, sigma = inputs\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        z = mu + tf.exp(0.5*sigma)*epsilon\n",
    "        return z \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layers(inputs, latent_dim):\n",
    "    ''' Defines the encoder's layers.\n",
    "    Args: \n",
    "        input: a batch from the dataset\n",
    "        latent_dim: dimensionality of the latent space\n",
    "        \n",
    "    Returns:\n",
    "        mu: learned mean\n",
    "        sigma: learned standard deviation\n",
    "        feature_shape: shape of the features before flattening\n",
    "    '''\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, \n",
    "                               padding='same', name='encode_conv1')(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU(0.1)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, \n",
    "                               padding='same', name='encode_conv2')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.1)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, \n",
    "                               padding='same', name='encode_conv3')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.1)(x)\n",
    "    features = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten(name='encoded_flatten')(features)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu', name='encode_dense')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    mu = tf.keras.layers.Dense(latent_dim, name='latent_mu')(x)\n",
    "    sigma = tf.keras.layers.Dense(latent_dim, name='latent_sigma')(x)\n",
    "    return mu, sigma, features.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(latent_dim, input_shape):\n",
    "    '''Define the encoder model with the Sampling layer\n",
    "    Args:\n",
    "        latent_dim: dimensionality of the latent space\n",
    "        input_shape: shape of a batch from the dataset\n",
    "    Returns:\n",
    "        model: the encoder model\n",
    "        feature_shape: shape of the features before flattening\n",
    "    '''\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    mu, sigma, feature_shape = encoder_layers(inputs=inputs, latent_dim=latent_dim)\n",
    "    z = Sampling()((mu, sigma))\n",
    "    # Trong class Sampling ko co __init__ >> Sampling()\n",
    "    # Func call co param \"inputs\", inputs = mu, sigma >> Sampling()((mu, sigma))\n",
    "    # hay inputs = tuple cua mu & sigma\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[mu, sigma, z])\n",
    "    # [mu, sigma, z] are the latent representations\n",
    "    model.summary()\n",
    "    return model, feature_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layers(inputs, feature_shape):\n",
    "    ''' Define the decoder layers\n",
    "    Args: \n",
    "        inputs: output of the encoder\n",
    "        feature_shape: shape of the features before flattening\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing the decoded output\n",
    "        '''\n",
    "    units = feature_shape[1] * feature_shape[2] * feature_shape[3]\n",
    "    x = tf.keras.layers.Dense(units, activation='relu', name='decode_dense1')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Reshape((feature_shape[1], feature_shape[2], feature_shape[3]), name='decode_reshape')(x)\n",
    "    \n",
    "    # Upsample the features back to the original dimension\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu', name='decode_conv_transpose1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='decode_conv_transpose2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)    \n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='decode_conv_transpose3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_model(latent_dim, feature_shape):\n",
    "    '''Defines the decoder model.\n",
    "    Args: \n",
    "        latent_dim: dimensionality of the latent space\n",
    "        conv_shape: shape of the features before flattening\n",
    "    Returns:\n",
    "        model: the decoder model \n",
    "    '''\n",
    "    inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
    "    outputs = decoder_layers(inputs, feature_shape)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(encoder, decoder, input_shape):\n",
    "    '''\n",
    "    Defines the VAE model:\n",
    "    Args:\n",
    "        encoder: encoder_model\n",
    "        decoder: decoder_model\n",
    "        input_shape: shape of the dataset_batch\n",
    "    Return:\n",
    "        VAE model\n",
    "    '''\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    mu, sigma, z = encoder(inputs)\n",
    "    reconstructed = decoder(z)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=reconstructed)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(input_shape, latent_dim):\n",
    "    encoder, feature_shape = encoder_model(latent_dim, input_shape)\n",
    "    decoder = decoder_model(latent_dim, feature_shape)\n",
    "    vae = vae_model(encoder, decoder, input_shape)\n",
    "\n",
    "    return encoder, decoder, vae \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " encode_conv1 (Conv2D)          (None, 32, 32, 32)   896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 32, 32, 32)   0           ['encode_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 32)  128         ['leaky_re_lu[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " encode_conv2 (Conv2D)          (None, 16, 16, 64)   18496       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 16, 16, 64)   0           ['encode_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 64)  256         ['leaky_re_lu_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " encode_conv3 (Conv2D)          (None, 8, 8, 64)     36928       ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 8, 8, 64)     0           ['encode_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['leaky_re_lu_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " encoded_flatten (Flatten)      (None, 4096)         0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " encode_dense (Dense)           (None, 1024)         4195328     ['encoded_flatten[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1024)        4096        ['encode_dense[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " latent_mu (Dense)              (None, 128)          131200      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " latent_sigma (Dense)           (None, 128)          131200      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 128)          0           ['latent_mu[0][0]',              \n",
      "                                                                  'latent_sigma[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,518,784\n",
      "Trainable params: 4,516,416\n",
      "Non-trainable params: 2,368\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " decode_dense1 (Dense)       (None, 4096)              528384    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " decode_reshape (Reshape)    (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " decode_conv_transpose1 (Con  (None, 16, 16, 128)      73856     \n",
      " v2DTranspose)                                                   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " decode_conv_transpose2 (Con  (None, 32, 32, 64)       73792     \n",
      " v2DTranspose)                                                   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " decode_conv_transpose3 (Con  (None, 64, 64, 32)       18464     \n",
      " v2DTranspose)                                                   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 64, 64, 3)        867       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 712,643\n",
      "Trainable params: 704,003\n",
      "Non-trainable params: 8,640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, vae = get_models(input_shape=(64,64,3,), latent_dim=LATENT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(image_data)//BATCH_SIZE\n",
    "val_steps = len(image_data)//BATCH_SIZE\n",
    "vae.compile(optimizer='adam', metrics=['accuracy'], loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "5/5 [==============================] - 1s 93ms/step - loss: 0.0272 - accuracy: 0.5566\n",
      "Epoch 2/5000\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0194 - accuracy: 0.5651\n",
      "Epoch 3/5000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0202 - accuracy: 0.5683\n",
      "Epoch 4/5000\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 0.0207 - accuracy: 0.5651\n",
      "Epoch 5/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0221 - accuracy: 0.5675\n",
      "Epoch 6/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0223 - accuracy: 0.5624\n",
      "Epoch 7/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0193 - accuracy: 0.5677\n",
      "Epoch 8/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0201 - accuracy: 0.5665\n",
      "Epoch 9/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0186 - accuracy: 0.5705\n",
      "Epoch 10/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0173 - accuracy: 0.5730\n",
      "Epoch 11/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0188 - accuracy: 0.5708\n",
      "Epoch 12/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0210 - accuracy: 0.5730\n",
      "Epoch 13/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0202 - accuracy: 0.5722\n",
      "Epoch 14/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0212 - accuracy: 0.5760\n",
      "Epoch 15/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0212 - accuracy: 0.5759\n",
      "Epoch 16/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0196 - accuracy: 0.5736\n",
      "Epoch 17/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0205 - accuracy: 0.5755\n",
      "Epoch 18/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0220 - accuracy: 0.5744\n",
      "Epoch 19/5000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.0213 - accuracy: 0.5787\n",
      "Epoch 20/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0213 - accuracy: 0.5828\n",
      "Epoch 21/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0190 - accuracy: 0.5820\n",
      "Epoch 22/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0201 - accuracy: 0.5813\n",
      "Epoch 23/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0191 - accuracy: 0.5813\n",
      "Epoch 24/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0183 - accuracy: 0.5855\n",
      "Epoch 25/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0191 - accuracy: 0.5829\n",
      "Epoch 26/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0211 - accuracy: 0.5822\n",
      "Epoch 27/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0194 - accuracy: 0.5868\n",
      "Epoch 28/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0197 - accuracy: 0.5882\n",
      "Epoch 29/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0203 - accuracy: 0.5895\n",
      "Epoch 30/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0195 - accuracy: 0.5890\n",
      "Epoch 31/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0204 - accuracy: 0.5908\n",
      "Epoch 32/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0197 - accuracy: 0.5896\n",
      "Epoch 33/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0195 - accuracy: 0.5906\n",
      "Epoch 34/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0229 - accuracy: 0.5907\n",
      "Epoch 35/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0207 - accuracy: 0.5923\n",
      "Epoch 36/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0204 - accuracy: 0.5937\n",
      "Epoch 37/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0173 - accuracy: 0.5952\n",
      "Epoch 38/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0175 - accuracy: 0.5937\n",
      "Epoch 39/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0191 - accuracy: 0.5923\n",
      "Epoch 40/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0202 - accuracy: 0.5958\n",
      "Epoch 41/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0219 - accuracy: 0.5938\n",
      "Epoch 42/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0192 - accuracy: 0.5929\n",
      "Epoch 43/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0200 - accuracy: 0.5978\n",
      "Epoch 44/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0183 - accuracy: 0.5977\n",
      "Epoch 45/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0178 - accuracy: 0.5977\n",
      "Epoch 46/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0164 - accuracy: 0.5964\n",
      "Epoch 47/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0203 - accuracy: 0.5975\n",
      "Epoch 48/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0195 - accuracy: 0.5991\n",
      "Epoch 49/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0173 - accuracy: 0.6010\n",
      "Epoch 50/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0195 - accuracy: 0.5976\n",
      "Epoch 51/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0158 - accuracy: 0.6018\n",
      "Epoch 52/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0181 - accuracy: 0.6006\n",
      "Epoch 53/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0199 - accuracy: 0.6017\n",
      "Epoch 54/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0155 - accuracy: 0.6037\n",
      "Epoch 55/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0191 - accuracy: 0.6031\n",
      "Epoch 56/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0171 - accuracy: 0.6045\n",
      "Epoch 57/5000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0212 - accuracy: 0.6022\n",
      "Epoch 58/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0169 - accuracy: 0.6043\n",
      "Epoch 59/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0182 - accuracy: 0.6038\n",
      "Epoch 60/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0175 - accuracy: 0.6027\n",
      "Epoch 61/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0160 - accuracy: 0.6007\n",
      "Epoch 62/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0191 - accuracy: 0.6041\n",
      "Epoch 63/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0180 - accuracy: 0.6036\n",
      "Epoch 64/5000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0179 - accuracy: 0.6062\n",
      "Epoch 65/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0151 - accuracy: 0.6060\n",
      "Epoch 66/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0168 - accuracy: 0.6064\n",
      "Epoch 67/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0222 - accuracy: 0.6053\n",
      "Epoch 68/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0218 - accuracy: 0.6023\n",
      "Epoch 69/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0159 - accuracy: 0.6062\n",
      "Epoch 70/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0191 - accuracy: 0.6075\n",
      "Epoch 71/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0173 - accuracy: 0.6071\n",
      "Epoch 72/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0207 - accuracy: 0.6065\n",
      "Epoch 73/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0205 - accuracy: 0.6048\n",
      "Epoch 74/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0161 - accuracy: 0.6078\n",
      "Epoch 75/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0174 - accuracy: 0.6080\n",
      "Epoch 76/5000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0175 - accuracy: 0.6050\n",
      "Epoch 77/5000\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.0178 - accuracy: 0.6084\n",
      "Epoch 78/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0180 - accuracy: 0.6045\n",
      "Epoch 79/5000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0187 - accuracy: 0.6079\n",
      "Epoch 80/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0179 - accuracy: 0.6069\n",
      "Epoch 81/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0193 - accuracy: 0.6070\n",
      "Epoch 82/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0161 - accuracy: 0.6083\n",
      "Epoch 83/5000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0182 - accuracy: 0.6052\n",
      "Epoch 84/5000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0189 - accuracy: 0.6092\n",
      "Epoch 85/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0185 - accuracy: 0.6074\n",
      "Epoch 86/5000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0176 - accuracy: 0.6074\n",
      "Epoch 87/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0174 - accuracy: 0.6070\n",
      "Epoch 88/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0179 - accuracy: 0.6073\n",
      "Epoch 89/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0167 - accuracy: 0.6089\n",
      "Epoch 90/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0171 - accuracy: 0.6073\n",
      "Epoch 91/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0179 - accuracy: 0.6072\n",
      "Epoch 92/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0180 - accuracy: 0.6100\n",
      "Epoch 93/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0168 - accuracy: 0.6077\n",
      "Epoch 94/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0178 - accuracy: 0.6079\n",
      "Epoch 95/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0175 - accuracy: 0.6086\n",
      "Epoch 96/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0150 - accuracy: 0.6094\n",
      "Epoch 97/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0193 - accuracy: 0.6061\n",
      "Epoch 98/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0157 - accuracy: 0.6089\n",
      "Epoch 99/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0140 - accuracy: 0.6097\n",
      "Epoch 100/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0181 - accuracy: 0.6081\n",
      "Epoch 101/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0128 - accuracy: 0.6106\n",
      "Epoch 102/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0159 - accuracy: 0.6092\n",
      "Epoch 103/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0171 - accuracy: 0.6076\n",
      "Epoch 104/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0158 - accuracy: 0.6100\n",
      "Epoch 105/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0174 - accuracy: 0.6083\n",
      "Epoch 106/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0133 - accuracy: 0.6103\n",
      "Epoch 107/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0198 - accuracy: 0.6084\n",
      "Epoch 108/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0176 - accuracy: 0.6094\n",
      "Epoch 109/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0183 - accuracy: 0.6083\n",
      "Epoch 110/5000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0169 - accuracy: 0.6073\n",
      "Epoch 111/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0156 - accuracy: 0.6086\n",
      "Epoch 112/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0169 - accuracy: 0.6100\n",
      "Epoch 113/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0169 - accuracy: 0.6088\n",
      "Epoch 114/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0163 - accuracy: 0.6087\n",
      "Epoch 115/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0172 - accuracy: 0.6079\n",
      "Epoch 116/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0174 - accuracy: 0.6095\n",
      "Epoch 117/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0141 - accuracy: 0.6086\n",
      "Epoch 118/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0154 - accuracy: 0.6088\n",
      "Epoch 119/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0140 - accuracy: 0.6082\n",
      "Epoch 120/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0168 - accuracy: 0.6077\n",
      "Epoch 121/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0171 - accuracy: 0.6079\n",
      "Epoch 122/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0197 - accuracy: 0.6095\n",
      "Epoch 123/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0155 - accuracy: 0.6076\n",
      "Epoch 124/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0171 - accuracy: 0.6069\n",
      "Epoch 125/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0179 - accuracy: 0.6087\n",
      "Epoch 126/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0185 - accuracy: 0.6072\n",
      "Epoch 127/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0171 - accuracy: 0.6087\n",
      "Epoch 128/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0149 - accuracy: 0.6088\n",
      "Epoch 129/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0171 - accuracy: 0.6093\n",
      "Epoch 130/5000\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.0160 - accuracy: 0.6092\n",
      "Epoch 131/5000\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 0.0151 - accuracy: 0.6101\n",
      "Epoch 132/5000\n",
      "5/5 [==============================] - 1s 86ms/step - loss: 0.0154 - accuracy: 0.6085\n",
      "Epoch 133/5000\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.0161 - accuracy: 0.6077\n",
      "Epoch 134/5000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0143 - accuracy: 0.6088\n",
      "Epoch 135/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0152 - accuracy: 0.6082\n",
      "Epoch 136/5000\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 0.0150 - accuracy: 0.6102\n",
      "Epoch 137/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0158 - accuracy: 0.6103\n",
      "Epoch 138/5000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0150 - accuracy: 0.6085\n",
      "Epoch 139/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0152 - accuracy: 0.6094\n",
      "Epoch 140/5000\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.0170 - accuracy: 0.6088\n",
      "Epoch 141/5000\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0156 - accuracy: 0.6073\n",
      "Epoch 142/5000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0161 - accuracy: 0.6070\n",
      "Epoch 143/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0160 - accuracy: 0.6075\n",
      "Epoch 144/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0147 - accuracy: 0.6102\n",
      "Epoch 145/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0178 - accuracy: 0.6068\n",
      "Epoch 146/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0148 - accuracy: 0.6075\n",
      "Epoch 147/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0136 - accuracy: 0.6113\n",
      "Epoch 148/5000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0146 - accuracy: 0.6092\n",
      "Epoch 149/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0167 - accuracy: 0.6080\n",
      "Epoch 150/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0191 - accuracy: 0.6076\n",
      "Epoch 151/5000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 0.0137 - accuracy: 0.6100\n",
      "Epoch 152/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0184 - accuracy: 0.6064\n",
      "Epoch 153/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0141 - accuracy: 0.6092\n",
      "Epoch 154/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0152 - accuracy: 0.6090\n",
      "Epoch 155/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0157 - accuracy: 0.6087\n",
      "Epoch 156/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0156 - accuracy: 0.6103\n",
      "Epoch 157/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0134 - accuracy: 0.6096\n",
      "Epoch 158/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0155 - accuracy: 0.6082\n",
      "Epoch 159/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0141 - accuracy: 0.6104\n",
      "Epoch 160/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0143 - accuracy: 0.6084\n",
      "Epoch 161/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0174 - accuracy: 0.6079\n",
      "Epoch 162/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0167 - accuracy: 0.6084\n",
      "Epoch 163/5000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0163 - accuracy: 0.6058\n",
      "Epoch 164/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0144 - accuracy: 0.6076\n",
      "Epoch 165/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0140 - accuracy: 0.6086\n",
      "Epoch 166/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0139 - accuracy: 0.6085\n",
      "Epoch 167/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0178 - accuracy: 0.6084\n",
      "Epoch 168/5000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0131 - accuracy: 0.6093\n",
      "Epoch 169/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0169 - accuracy: 0.6098\n",
      "Epoch 170/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0153 - accuracy: 0.6073\n",
      "Epoch 171/5000\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 0.0166 - accuracy: 0.6098\n",
      "Epoch 172/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0148 - accuracy: 0.6095\n",
      "Epoch 173/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0137 - accuracy: 0.6097\n",
      "Epoch 174/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0161 - accuracy: 0.6079\n",
      "Epoch 175/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0161 - accuracy: 0.6102\n",
      "Epoch 176/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0155 - accuracy: 0.6083\n",
      "Epoch 177/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0139 - accuracy: 0.6084\n",
      "Epoch 178/5000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0144 - accuracy: 0.6106\n",
      "Epoch 179/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0131 - accuracy: 0.6102\n",
      "Epoch 180/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0161 - accuracy: 0.6062\n",
      "Epoch 181/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0140 - accuracy: 0.6065\n",
      "Epoch 182/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0139 - accuracy: 0.6102\n",
      "Epoch 183/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0148 - accuracy: 0.6085\n",
      "Epoch 184/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0139 - accuracy: 0.6094\n",
      "Epoch 185/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0129 - accuracy: 0.6119\n",
      "Epoch 186/5000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0145 - accuracy: 0.6076\n",
      "Epoch 187/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0148 - accuracy: 0.6098\n",
      "Epoch 188/5000\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.0141 - accuracy: 0.6092\n",
      "Epoch 189/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0141 - accuracy: 0.6096\n",
      "Epoch 190/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0173 - accuracy: 0.6083\n",
      "Epoch 191/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0168 - accuracy: 0.6092\n",
      "Epoch 192/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0140 - accuracy: 0.6089\n",
      "Epoch 193/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0151 - accuracy: 0.6067\n",
      "Epoch 194/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0121 - accuracy: 0.6094\n",
      "Epoch 195/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0130 - accuracy: 0.6098\n",
      "Epoch 196/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0137 - accuracy: 0.6087\n",
      "Epoch 197/5000\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.0140 - accuracy: 0.6098\n",
      "Epoch 198/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0150 - accuracy: 0.6101\n",
      "Epoch 199/5000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0135 - accuracy: 0.6109\n",
      "Epoch 200/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0139 - accuracy: 0.6074\n",
      "Epoch 201/5000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0164 - accuracy: 0.6123\n",
      "Epoch 202/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0141 - accuracy: 0.6102\n",
      "Epoch 203/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0134 - accuracy: 0.6100\n",
      "Epoch 204/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0129 - accuracy: 0.6086\n",
      "Epoch 205/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0135 - accuracy: 0.6103\n",
      "Epoch 206/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0129 - accuracy: 0.6100\n",
      "Epoch 207/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0138 - accuracy: 0.6091\n",
      "Epoch 208/5000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0144 - accuracy: 0.6084\n",
      "Epoch 209/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0127 - accuracy: 0.6078\n",
      "Epoch 210/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0124 - accuracy: 0.6094\n",
      "Epoch 211/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0161 - accuracy: 0.6082\n",
      "Epoch 212/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0145 - accuracy: 0.6084\n",
      "Epoch 213/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0134 - accuracy: 0.6102\n",
      "Epoch 214/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0115 - accuracy: 0.6091\n",
      "Epoch 215/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0151 - accuracy: 0.6098\n",
      "Epoch 216/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0118 - accuracy: 0.6102\n",
      "Epoch 217/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0135 - accuracy: 0.6098\n",
      "Epoch 218/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0143 - accuracy: 0.6098\n",
      "Epoch 219/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0138 - accuracy: 0.6105\n",
      "Epoch 220/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0128 - accuracy: 0.6097\n",
      "Epoch 221/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0146 - accuracy: 0.6087\n",
      "Epoch 222/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0136 - accuracy: 0.6116\n",
      "Epoch 223/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0169 - accuracy: 0.6078\n",
      "Epoch 224/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0117 - accuracy: 0.6068\n",
      "Epoch 225/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0132 - accuracy: 0.6073\n",
      "Epoch 226/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0121 - accuracy: 0.6100\n",
      "Epoch 227/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0148 - accuracy: 0.6077\n",
      "Epoch 228/5000\n",
      "5/5 [==============================] - 0s 109ms/step - loss: 0.0121 - accuracy: 0.6075\n",
      "Epoch 229/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0153 - accuracy: 0.6068\n",
      "Epoch 230/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0141 - accuracy: 0.6087\n",
      "Epoch 231/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0146 - accuracy: 0.6070\n",
      "Epoch 232/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0133 - accuracy: 0.6072\n",
      "Epoch 233/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0137 - accuracy: 0.6097\n",
      "Epoch 234/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0130 - accuracy: 0.6083\n",
      "Epoch 235/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0122 - accuracy: 0.6086\n",
      "Epoch 236/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0131 - accuracy: 0.6099\n",
      "Epoch 237/5000\n",
      "5/5 [==============================] - 1s 86ms/step - loss: 0.0111 - accuracy: 0.6110\n",
      "Epoch 238/5000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0135 - accuracy: 0.6106\n",
      "Epoch 239/5000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 0.0136 - accuracy: 0.6101\n",
      "Epoch 240/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0124 - accuracy: 0.6096\n",
      "Epoch 241/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0121 - accuracy: 0.6091\n",
      "Epoch 242/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0116 - accuracy: 0.6088\n",
      "Epoch 243/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0120 - accuracy: 0.6097\n",
      "Epoch 244/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0118 - accuracy: 0.6105\n",
      "Epoch 245/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0105 - accuracy: 0.6110\n",
      "Epoch 246/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0141 - accuracy: 0.6090\n",
      "Epoch 247/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0133 - accuracy: 0.6100\n",
      "Epoch 248/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0130 - accuracy: 0.6089\n",
      "Epoch 249/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0123 - accuracy: 0.6100\n",
      "Epoch 250/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0149 - accuracy: 0.6107\n",
      "Epoch 251/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0114 - accuracy: 0.6083\n",
      "Epoch 252/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0146 - accuracy: 0.6085\n",
      "Epoch 253/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0122 - accuracy: 0.6087\n",
      "Epoch 254/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0148 - accuracy: 0.6083\n",
      "Epoch 255/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0123 - accuracy: 0.6104\n",
      "Epoch 256/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0118 - accuracy: 0.6084\n",
      "Epoch 257/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0112 - accuracy: 0.6088\n",
      "Epoch 258/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0119 - accuracy: 0.6094\n",
      "Epoch 259/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0102 - accuracy: 0.6111\n",
      "Epoch 260/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0141 - accuracy: 0.6095\n",
      "Epoch 261/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0143 - accuracy: 0.6088\n",
      "Epoch 262/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0145 - accuracy: 0.6105\n",
      "Epoch 263/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0139 - accuracy: 0.6113\n",
      "Epoch 264/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0106 - accuracy: 0.6101\n",
      "Epoch 265/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0122 - accuracy: 0.6112\n",
      "Epoch 266/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0150 - accuracy: 0.6078\n",
      "Epoch 267/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0127 - accuracy: 0.6074\n",
      "Epoch 268/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0129 - accuracy: 0.6084\n",
      "Epoch 269/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0125 - accuracy: 0.6110\n",
      "Epoch 270/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0121 - accuracy: 0.6102\n",
      "Epoch 271/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0156 - accuracy: 0.6098\n",
      "Epoch 272/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0129 - accuracy: 0.6097\n",
      "Epoch 273/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0127 - accuracy: 0.6106\n",
      "Epoch 274/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0134 - accuracy: 0.6104\n",
      "Epoch 275/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0135 - accuracy: 0.6113\n",
      "Epoch 276/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0122 - accuracy: 0.6095\n",
      "Epoch 277/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0121 - accuracy: 0.6081\n",
      "Epoch 278/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0115 - accuracy: 0.6084\n",
      "Epoch 279/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0143 - accuracy: 0.6107\n",
      "Epoch 280/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0110 - accuracy: 0.6097\n",
      "Epoch 281/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0120 - accuracy: 0.6104\n",
      "Epoch 282/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0123 - accuracy: 0.6092\n",
      "Epoch 283/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0135 - accuracy: 0.6098\n",
      "Epoch 284/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0111 - accuracy: 0.6102\n",
      "Epoch 285/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0096 - accuracy: 0.6101\n",
      "Epoch 286/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0121 - accuracy: 0.6096\n",
      "Epoch 287/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0130 - accuracy: 0.6125\n",
      "Epoch 288/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0134 - accuracy: 0.6101\n",
      "Epoch 289/5000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.0126 - accuracy: 0.6090\n",
      "Epoch 290/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0104 - accuracy: 0.6103\n",
      "Epoch 291/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0128 - accuracy: 0.6101\n",
      "Epoch 292/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0130 - accuracy: 0.6104\n",
      "Epoch 293/5000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0117 - accuracy: 0.6098\n",
      "Epoch 294/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0130 - accuracy: 0.6085\n",
      "Epoch 295/5000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0128 - accuracy: 0.6098\n",
      "Epoch 296/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0116 - accuracy: 0.6108\n",
      "Epoch 297/5000\n",
      "5/5 [==============================] - 0s 102ms/step - loss: 0.0101 - accuracy: 0.6110\n",
      "Epoch 298/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0123 - accuracy: 0.6099\n",
      "Epoch 299/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0110 - accuracy: 0.6102\n",
      "Epoch 300/5000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0112 - accuracy: 0.6092\n",
      "Epoch 301/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0123 - accuracy: 0.6108\n",
      "Epoch 302/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0119 - accuracy: 0.6088\n",
      "Epoch 303/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0113 - accuracy: 0.6091\n",
      "Epoch 304/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0125 - accuracy: 0.6096\n",
      "Epoch 305/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0134 - accuracy: 0.6091\n",
      "Epoch 306/5000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0123 - accuracy: 0.6097\n",
      "Epoch 307/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0101 - accuracy: 0.6093\n",
      "Epoch 308/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0105 - accuracy: 0.6119\n",
      "Epoch 309/5000\n",
      "5/5 [==============================] - 1s 82ms/step - loss: 0.0122 - accuracy: 0.6093\n",
      "Epoch 310/5000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0136 - accuracy: 0.6105\n",
      "Epoch 311/5000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0122 - accuracy: 0.6078\n",
      "Epoch 312/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0102 - accuracy: 0.6119\n",
      "Epoch 313/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0134 - accuracy: 0.6091\n",
      "Epoch 314/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0129 - accuracy: 0.6096\n",
      "Epoch 315/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0131 - accuracy: 0.6097\n",
      "Epoch 316/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0145 - accuracy: 0.6095\n",
      "Epoch 317/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0132 - accuracy: 0.6084\n",
      "Epoch 318/5000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0101 - accuracy: 0.6105\n",
      "Epoch 319/5000\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0115 - accuracy: 0.6122\n",
      "Epoch 320/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0109 - accuracy: 0.6139\n",
      "Epoch 321/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0104 - accuracy: 0.6106\n",
      "Epoch 322/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0110 - accuracy: 0.6108\n",
      "Epoch 323/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0118 - accuracy: 0.6107\n",
      "Epoch 324/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0116 - accuracy: 0.6129\n",
      "Epoch 325/5000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0122 - accuracy: 0.6081\n",
      "Epoch 326/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0115 - accuracy: 0.6099\n",
      "Epoch 327/5000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0103 - accuracy: 0.6131\n",
      "Epoch 328/5000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0102 - accuracy: 0.6117\n",
      "Epoch 329/5000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0136 - accuracy: 0.6094\n",
      "Epoch 330/5000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0125 - accuracy: 0.6099\n",
      "Epoch 331/5000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0134 - accuracy: 0.6105\n",
      "Epoch 332/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0114 - accuracy: 0.6102\n",
      "Epoch 333/5000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0106 - accuracy: 0.6121\n",
      "Epoch 334/5000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0112 - accuracy: 0.6112\n",
      "Epoch 335/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0130 - accuracy: 0.6099\n",
      "Epoch 336/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0121 - accuracy: 0.6094\n",
      "Epoch 337/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0118 - accuracy: 0.6093\n",
      "Epoch 338/5000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0103 - accuracy: 0.6094\n",
      "Epoch 339/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0108 - accuracy: 0.6109\n",
      "Epoch 340/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0096 - accuracy: 0.6112\n",
      "Epoch 341/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0132 - accuracy: 0.6092\n",
      "Epoch 342/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0113 - accuracy: 0.6099\n",
      "Epoch 343/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0123 - accuracy: 0.6109\n",
      "Epoch 344/5000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0125 - accuracy: 0.6102\n",
      "Epoch 345/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0109 - accuracy: 0.6103\n",
      "Epoch 346/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0132 - accuracy: 0.6083\n",
      "Epoch 347/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0111 - accuracy: 0.6102\n",
      "Epoch 348/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0118 - accuracy: 0.6117\n",
      "Epoch 349/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0143 - accuracy: 0.6107\n",
      "Epoch 350/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0110 - accuracy: 0.6116\n",
      "Epoch 351/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0119 - accuracy: 0.6088\n",
      "Epoch 352/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0102 - accuracy: 0.6107\n",
      "Epoch 353/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0105 - accuracy: 0.6109\n",
      "Epoch 354/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0121 - accuracy: 0.6099\n",
      "Epoch 355/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0108 - accuracy: 0.6097\n",
      "Epoch 356/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0106 - accuracy: 0.6124\n",
      "Epoch 357/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0108 - accuracy: 0.6116\n",
      "Epoch 358/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0120 - accuracy: 0.6116\n",
      "Epoch 359/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0116 - accuracy: 0.6099\n",
      "Epoch 360/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0116 - accuracy: 0.6107\n",
      "Epoch 361/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0093 - accuracy: 0.6098\n",
      "Epoch 362/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0125 - accuracy: 0.6107\n",
      "Epoch 363/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0102 - accuracy: 0.6125\n",
      "Epoch 364/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0108 - accuracy: 0.6124\n",
      "Epoch 365/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0126 - accuracy: 0.6101\n",
      "Epoch 366/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0107 - accuracy: 0.6093\n",
      "Epoch 367/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0138 - accuracy: 0.6098\n",
      "Epoch 368/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0104 - accuracy: 0.6123\n",
      "Epoch 369/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0134 - accuracy: 0.6104\n",
      "Epoch 370/5000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0115 - accuracy: 0.6128\n",
      "Epoch 371/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0137 - accuracy: 0.6094\n",
      "Epoch 372/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0111 - accuracy: 0.6122\n",
      "Epoch 373/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0141 - accuracy: 0.6122\n",
      "Epoch 374/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0113 - accuracy: 0.6104\n",
      "Epoch 375/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0094 - accuracy: 0.6112\n",
      "Epoch 376/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0106 - accuracy: 0.6113\n",
      "Epoch 377/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0124 - accuracy: 0.6091\n",
      "Epoch 378/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0128 - accuracy: 0.6105\n",
      "Epoch 379/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0109 - accuracy: 0.6123\n",
      "Epoch 380/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0108 - accuracy: 0.6123\n",
      "Epoch 381/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0111 - accuracy: 0.6104\n",
      "Epoch 382/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0128 - accuracy: 0.6112\n",
      "Epoch 383/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0106 - accuracy: 0.6120\n",
      "Epoch 384/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0092 - accuracy: 0.6134\n",
      "Epoch 385/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0098 - accuracy: 0.6108\n",
      "Epoch 386/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0120 - accuracy: 0.6100\n",
      "Epoch 387/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0124 - accuracy: 0.6114\n",
      "Epoch 388/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0118 - accuracy: 0.6105\n",
      "Epoch 389/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0108 - accuracy: 0.6111\n",
      "Epoch 390/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0111 - accuracy: 0.6094\n",
      "Epoch 391/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0104 - accuracy: 0.6095\n",
      "Epoch 392/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0093 - accuracy: 0.6107\n",
      "Epoch 393/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0096 - accuracy: 0.6114\n",
      "Epoch 394/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0118 - accuracy: 0.6102\n",
      "Epoch 395/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0108 - accuracy: 0.6099\n",
      "Epoch 396/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0101 - accuracy: 0.6111\n",
      "Epoch 397/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0116 - accuracy: 0.6121\n",
      "Epoch 398/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0124 - accuracy: 0.6117\n",
      "Epoch 399/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0117 - accuracy: 0.6100\n",
      "Epoch 400/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0115 - accuracy: 0.6126\n",
      "Epoch 401/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0116 - accuracy: 0.6100\n",
      "Epoch 402/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0111 - accuracy: 0.6115\n",
      "Epoch 403/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0110 - accuracy: 0.6110\n",
      "Epoch 404/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0096 - accuracy: 0.6109\n",
      "Epoch 405/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0118 - accuracy: 0.6104\n",
      "Epoch 406/5000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0112 - accuracy: 0.6100\n",
      "Epoch 407/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0120 - accuracy: 0.6124\n",
      "Epoch 408/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0109 - accuracy: 0.6138\n",
      "Epoch 409/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0103 - accuracy: 0.6128\n",
      "Epoch 410/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0104 - accuracy: 0.6109\n",
      "Epoch 411/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0099 - accuracy: 0.6118\n",
      "Epoch 412/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0091 - accuracy: 0.6110\n",
      "Epoch 413/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0098 - accuracy: 0.6115\n",
      "Epoch 414/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0103 - accuracy: 0.6147\n",
      "Epoch 415/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0100 - accuracy: 0.6131\n",
      "Epoch 416/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0100 - accuracy: 0.6097\n",
      "Epoch 417/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0093 - accuracy: 0.6113\n",
      "Epoch 418/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0099 - accuracy: 0.6119\n",
      "Epoch 419/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0096 - accuracy: 0.6122\n",
      "Epoch 420/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0106 - accuracy: 0.6129\n",
      "Epoch 421/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0092 - accuracy: 0.6122\n",
      "Epoch 422/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0109 - accuracy: 0.6103\n",
      "Epoch 423/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0086 - accuracy: 0.6129\n",
      "Epoch 424/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0104 - accuracy: 0.6136\n",
      "Epoch 425/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0115 - accuracy: 0.6118\n",
      "Epoch 426/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0105 - accuracy: 0.6116\n",
      "Epoch 427/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0107 - accuracy: 0.6130\n",
      "Epoch 428/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0098 - accuracy: 0.6102\n",
      "Epoch 429/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0093 - accuracy: 0.6109\n",
      "Epoch 430/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0084 - accuracy: 0.6105\n",
      "Epoch 431/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0103 - accuracy: 0.6104\n",
      "Epoch 432/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0117 - accuracy: 0.6121\n",
      "Epoch 433/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0103 - accuracy: 0.6133\n",
      "Epoch 434/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0107 - accuracy: 0.6125\n",
      "Epoch 435/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0088 - accuracy: 0.6124\n",
      "Epoch 436/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0084 - accuracy: 0.6127\n",
      "Epoch 437/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0092 - accuracy: 0.6122\n",
      "Epoch 438/5000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.0100 - accuracy: 0.6126\n",
      "Epoch 439/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0109 - accuracy: 0.6121\n",
      "Epoch 440/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0092 - accuracy: 0.6122\n",
      "Epoch 441/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0112 - accuracy: 0.6120\n",
      "Epoch 442/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0089 - accuracy: 0.6118\n",
      "Epoch 443/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0120 - accuracy: 0.6130\n",
      "Epoch 444/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0110 - accuracy: 0.6115\n",
      "Epoch 445/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0076 - accuracy: 0.6137\n",
      "Epoch 446/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0096 - accuracy: 0.6136\n",
      "Epoch 447/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0114 - accuracy: 0.6113\n",
      "Epoch 448/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0102 - accuracy: 0.6127\n",
      "Epoch 449/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0095 - accuracy: 0.6132\n",
      "Epoch 450/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0098 - accuracy: 0.6120\n",
      "Epoch 451/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0093 - accuracy: 0.6115\n",
      "Epoch 452/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0118 - accuracy: 0.6123\n",
      "Epoch 453/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0110 - accuracy: 0.6127\n",
      "Epoch 454/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0098 - accuracy: 0.6115\n",
      "Epoch 455/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0089 - accuracy: 0.6134\n",
      "Epoch 456/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0074 - accuracy: 0.6132\n",
      "Epoch 457/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0105 - accuracy: 0.6119\n",
      "Epoch 458/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0104 - accuracy: 0.6125\n",
      "Epoch 459/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0111 - accuracy: 0.6117\n",
      "Epoch 460/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0099 - accuracy: 0.6108\n",
      "Epoch 461/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0121 - accuracy: 0.6119\n",
      "Epoch 462/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0109 - accuracy: 0.6115\n",
      "Epoch 463/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0093 - accuracy: 0.6127\n",
      "Epoch 464/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0091 - accuracy: 0.6115\n",
      "Epoch 465/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0103 - accuracy: 0.6096\n",
      "Epoch 466/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0089 - accuracy: 0.6118\n",
      "Epoch 467/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0115 - accuracy: 0.6118\n",
      "Epoch 468/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0102 - accuracy: 0.6124\n",
      "Epoch 469/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0103 - accuracy: 0.6110\n",
      "Epoch 470/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0092 - accuracy: 0.6113\n",
      "Epoch 471/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0080 - accuracy: 0.6131\n",
      "Epoch 472/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0086 - accuracy: 0.6120\n",
      "Epoch 473/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0083 - accuracy: 0.6109\n",
      "Epoch 474/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0117 - accuracy: 0.6105\n",
      "Epoch 475/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0090 - accuracy: 0.6122\n",
      "Epoch 476/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0102 - accuracy: 0.6123\n",
      "Epoch 477/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0092 - accuracy: 0.6122\n",
      "Epoch 478/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0090 - accuracy: 0.6116\n",
      "Epoch 479/5000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0085 - accuracy: 0.6106\n",
      "Epoch 480/5000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0106 - accuracy: 0.6110\n",
      "Epoch 481/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0070 - accuracy: 0.6120\n",
      "Epoch 482/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0120 - accuracy: 0.6112\n",
      "Epoch 483/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0086 - accuracy: 0.6121\n",
      "Epoch 484/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0103 - accuracy: 0.6097\n",
      "Epoch 485/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0083 - accuracy: 0.6104\n",
      "Epoch 486/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0103 - accuracy: 0.6109\n",
      "Epoch 487/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0119 - accuracy: 0.6103\n",
      "Epoch 488/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0097 - accuracy: 0.6131\n",
      "Epoch 489/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0117 - accuracy: 0.6120\n",
      "Epoch 490/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0108 - accuracy: 0.6106\n",
      "Epoch 491/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0105 - accuracy: 0.6114\n",
      "Epoch 492/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0112 - accuracy: 0.6116\n",
      "Epoch 493/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0098 - accuracy: 0.6119\n",
      "Epoch 494/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0094 - accuracy: 0.6111\n",
      "Epoch 495/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0096 - accuracy: 0.6125\n",
      "Epoch 496/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0090 - accuracy: 0.6125\n",
      "Epoch 497/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0106 - accuracy: 0.6106\n",
      "Epoch 498/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0095 - accuracy: 0.6130\n",
      "Epoch 499/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0095 - accuracy: 0.6123\n",
      "Epoch 500/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0122 - accuracy: 0.6091\n",
      "Epoch 501/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0110 - accuracy: 0.6104\n",
      "Epoch 502/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0093 - accuracy: 0.6117\n",
      "Epoch 503/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0105 - accuracy: 0.6095\n",
      "Epoch 504/5000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0105 - accuracy: 0.6109\n",
      "Epoch 505/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0079 - accuracy: 0.6124\n",
      "Epoch 506/5000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.0112 - accuracy: 0.6111\n",
      "Epoch 507/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0099 - accuracy: 0.6115\n",
      "Epoch 508/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0093 - accuracy: 0.6117\n",
      "Epoch 509/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0102 - accuracy: 0.6123\n",
      "Epoch 510/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0106 - accuracy: 0.6116\n",
      "Epoch 511/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0073 - accuracy: 0.6117\n",
      "Epoch 512/5000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0073 - accuracy: 0.6132\n",
      "Epoch 513/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0092 - accuracy: 0.6115\n",
      "Epoch 514/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0101 - accuracy: 0.6102\n",
      "Epoch 515/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0085 - accuracy: 0.6121\n",
      "Epoch 516/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0103 - accuracy: 0.6114\n",
      "Epoch 517/5000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0084 - accuracy: 0.6114\n",
      "Epoch 518/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0093 - accuracy: 0.6116\n",
      "Epoch 519/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0107 - accuracy: 0.6109\n",
      "Epoch 520/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0104 - accuracy: 0.6096\n",
      "Epoch 521/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0112 - accuracy: 0.6108\n",
      "Epoch 522/5000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0101 - accuracy: 0.6104\n",
      "Epoch 523/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0090 - accuracy: 0.6109\n",
      "Epoch 524/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0089 - accuracy: 0.6104\n",
      "Epoch 525/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0109 - accuracy: 0.6106\n",
      "Epoch 526/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0096 - accuracy: 0.6128\n",
      "Epoch 527/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0097 - accuracy: 0.6117\n",
      "Epoch 528/5000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.0116 - accuracy: 0.6121\n",
      "Epoch 529/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0100 - accuracy: 0.6125\n",
      "Epoch 530/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0092 - accuracy: 0.6097\n",
      "Epoch 531/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0087 - accuracy: 0.6107\n",
      "Epoch 532/5000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0094 - accuracy: 0.6099\n",
      "Epoch 533/5000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0093 - accuracy: 0.6105\n",
      "Epoch 534/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0082 - accuracy: 0.6120\n",
      "Epoch 535/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0095 - accuracy: 0.6106\n",
      "Epoch 536/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0094 - accuracy: 0.6121\n",
      "Epoch 537/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0112 - accuracy: 0.6122\n",
      "Epoch 538/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0089 - accuracy: 0.6108\n",
      "Epoch 539/5000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.0097 - accuracy: 0.6110\n",
      "Epoch 540/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0091 - accuracy: 0.6106\n",
      "Epoch 541/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0103 - accuracy: 0.6126\n",
      "Epoch 542/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0096 - accuracy: 0.6112\n",
      "Epoch 543/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0089 - accuracy: 0.6118\n",
      "Epoch 544/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0098 - accuracy: 0.6102\n",
      "Epoch 545/5000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0086 - accuracy: 0.6123\n",
      "Epoch 546/5000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0101 - accuracy: 0.6108\n",
      "Epoch 547/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0118 - accuracy: 0.6122\n",
      "Epoch 548/5000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0099 - accuracy: 0.6117\n",
      "Epoch 549/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0085 - accuracy: 0.6101\n",
      "Epoch 550/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0087 - accuracy: 0.6130\n",
      "Epoch 551/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0105 - accuracy: 0.6119\n",
      "Epoch 552/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0088 - accuracy: 0.6140\n",
      "Epoch 553/5000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0100 - accuracy: 0.6125\n",
      "Epoch 554/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0091 - accuracy: 0.6114\n",
      "Epoch 555/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0090 - accuracy: 0.6135\n",
      "Epoch 556/5000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0089 - accuracy: 0.6114\n",
      "Epoch 557/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0089 - accuracy: 0.6121\n",
      "Epoch 558/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0122 - accuracy: 0.6121\n",
      "Epoch 559/5000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0073 - accuracy: 0.6128\n",
      "Epoch 560/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0095 - accuracy: 0.6116\n",
      "Epoch 561/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0087 - accuracy: 0.6126\n",
      "Epoch 562/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0084 - accuracy: 0.6115\n",
      "Epoch 563/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0119 - accuracy: 0.6100\n",
      "Epoch 564/5000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.0107 - accuracy: 0.6118\n",
      "Epoch 565/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0104 - accuracy: 0.6100\n",
      "Epoch 566/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0100 - accuracy: 0.6116\n",
      "Epoch 567/5000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0098 - accuracy: 0.6121\n",
      "Epoch 568/5000\n",
      "5/5 [==============================] - 1s 111ms/step - loss: 0.0096 - accuracy: 0.6137\n",
      "Epoch 569/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0101 - accuracy: 0.6088\n",
      "Epoch 570/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0087 - accuracy: 0.6118\n",
      "Epoch 571/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0089 - accuracy: 0.6120\n",
      "Epoch 572/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0092 - accuracy: 0.6124\n",
      "Epoch 573/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0113 - accuracy: 0.6123\n",
      "Epoch 574/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0089 - accuracy: 0.6132\n",
      "Epoch 575/5000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0097 - accuracy: 0.6118\n",
      "Epoch 576/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0092 - accuracy: 0.6124\n",
      "Epoch 577/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0081 - accuracy: 0.6119\n",
      "Epoch 578/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0092 - accuracy: 0.6091\n",
      "Epoch 579/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0102 - accuracy: 0.6133\n",
      "Epoch 580/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0076 - accuracy: 0.6123\n",
      "Epoch 581/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0082 - accuracy: 0.6111\n",
      "Epoch 582/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0098 - accuracy: 0.6125\n",
      "Epoch 583/5000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0092 - accuracy: 0.6106\n",
      "Epoch 584/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0099 - accuracy: 0.6123\n",
      "Epoch 585/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0087 - accuracy: 0.6115\n",
      "Epoch 586/5000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0098 - accuracy: 0.6119\n",
      "Epoch 587/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0093 - accuracy: 0.6118\n",
      "Epoch 588/5000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.0086 - accuracy: 0.6121\n",
      "Epoch 589/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0082 - accuracy: 0.6130\n",
      "Epoch 590/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0102 - accuracy: 0.6114\n",
      "Epoch 591/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0088 - accuracy: 0.6130\n",
      "Epoch 592/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0081 - accuracy: 0.6129\n",
      "Epoch 593/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0091 - accuracy: 0.6108\n",
      "Epoch 594/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0084 - accuracy: 0.6109\n",
      "Epoch 595/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0088 - accuracy: 0.6117\n",
      "Epoch 596/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0090 - accuracy: 0.6116\n",
      "Epoch 597/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0080 - accuracy: 0.6132\n",
      "Epoch 598/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0103 - accuracy: 0.6108\n",
      "Epoch 599/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0076 - accuracy: 0.6125\n",
      "Epoch 600/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0111 - accuracy: 0.6115\n",
      "Epoch 601/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0088 - accuracy: 0.6117\n",
      "Epoch 602/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0087 - accuracy: 0.6122\n",
      "Epoch 603/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0079 - accuracy: 0.6101\n",
      "Epoch 604/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0085 - accuracy: 0.6104\n",
      "Epoch 605/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0100 - accuracy: 0.6122\n",
      "Epoch 606/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0099 - accuracy: 0.6112\n",
      "Epoch 607/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0107 - accuracy: 0.6105\n",
      "Epoch 608/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0101 - accuracy: 0.6135\n",
      "Epoch 609/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0082 - accuracy: 0.6130\n",
      "Epoch 610/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0092 - accuracy: 0.6109\n",
      "Epoch 611/5000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 0.0135 - accuracy: 0.6109\n",
      "Epoch 612/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0108 - accuracy: 0.6112\n",
      "Epoch 613/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0091 - accuracy: 0.6110\n",
      "Epoch 614/5000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0101 - accuracy: 0.6119\n",
      "Epoch 615/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0086 - accuracy: 0.6125\n",
      "Epoch 616/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0097 - accuracy: 0.6122\n",
      "Epoch 617/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0098 - accuracy: 0.6123\n",
      "Epoch 618/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0095 - accuracy: 0.6113\n",
      "Epoch 619/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0107 - accuracy: 0.6112\n",
      "Epoch 620/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0097 - accuracy: 0.6102\n",
      "Epoch 621/5000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0083 - accuracy: 0.6119\n",
      "Epoch 622/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0103 - accuracy: 0.6115\n",
      "Epoch 623/5000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0099 - accuracy: 0.6116\n",
      "Epoch 624/5000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0081 - accuracy: 0.6123\n",
      "Epoch 625/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0084 - accuracy: 0.6110\n",
      "Epoch 626/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0088 - accuracy: 0.6130\n",
      "Epoch 627/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0102 - accuracy: 0.6125\n",
      "Epoch 628/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0081 - accuracy: 0.6115\n",
      "Epoch 629/5000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0083 - accuracy: 0.6098\n",
      "Epoch 630/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0107 - accuracy: 0.6085\n",
      "Epoch 631/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0091 - accuracy: 0.6101\n",
      "Epoch 632/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0085 - accuracy: 0.6120\n",
      "Epoch 633/5000\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 0.0085 - accuracy: 0.6123\n",
      "Epoch 634/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0089 - accuracy: 0.6114\n",
      "Epoch 635/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0085 - accuracy: 0.6120\n",
      "Epoch 636/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0089 - accuracy: 0.6127\n",
      "Epoch 637/5000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0081 - accuracy: 0.6118\n",
      "Epoch 638/5000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0103 - accuracy: 0.6108\n",
      "Epoch 639/5000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0088 - accuracy: 0.6106\n",
      "Epoch 640/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0087 - accuracy: 0.6105\n",
      "Epoch 641/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0086 - accuracy: 0.6143\n",
      "Epoch 642/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0091 - accuracy: 0.6125\n",
      "Epoch 643/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0098 - accuracy: 0.6117\n",
      "Epoch 644/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0088 - accuracy: 0.6117\n",
      "Epoch 645/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0096 - accuracy: 0.6117\n",
      "Epoch 646/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0075 - accuracy: 0.6107\n",
      "Epoch 647/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0100 - accuracy: 0.6102\n",
      "Epoch 648/5000\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 0.0082 - accuracy: 0.6127\n",
      "Epoch 649/5000\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0096 - accuracy: 0.6115\n",
      "Epoch 650/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0102 - accuracy: 0.6130\n",
      "Epoch 651/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0088 - accuracy: 0.6125\n",
      "Epoch 652/5000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.0076 - accuracy: 0.6120\n",
      "Epoch 653/5000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0102 - accuracy: 0.6125\n",
      "Epoch 654/5000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0087 - accuracy: 0.6123\n",
      "Epoch 655/5000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0093 - accuracy: 0.6124\n",
      "Epoch 656/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0090 - accuracy: 0.6132\n",
      "Epoch 657/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0099 - accuracy: 0.6133\n",
      "Epoch 658/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0086 - accuracy: 0.6128\n",
      "Epoch 659/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0080 - accuracy: 0.6123\n",
      "Epoch 660/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0106 - accuracy: 0.6109\n",
      "Epoch 661/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0102 - accuracy: 0.6114\n",
      "Epoch 662/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0080 - accuracy: 0.6123\n",
      "Epoch 663/5000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0091 - accuracy: 0.6120\n",
      "Epoch 664/5000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0088 - accuracy: 0.6113\n",
      "Epoch 665/5000\n",
      "5/5 [==============================] - 1s 78ms/step - loss: 0.0091 - accuracy: 0.6137\n",
      "Epoch 666/5000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0088 - accuracy: 0.6116\n",
      "Epoch 667/5000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0091 - accuracy: 0.6112\n",
      "Epoch 668/5000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 0.0081 - accuracy: 0.6136\n",
      "Epoch 669/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0078 - accuracy: 0.6122\n",
      "Epoch 670/5000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0089 - accuracy: 0.6127\n",
      "Epoch 671/5000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0096 - accuracy: 0.6118\n",
      "Epoch 672/5000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0107 - accuracy: 0.6103\n",
      "Epoch 673/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0082 - accuracy: 0.6117\n",
      "Epoch 674/5000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0098 - accuracy: 0.6101\n",
      "Epoch 675/5000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 0.0092 - accuracy: 0.6116\n",
      "Epoch 676/5000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0088 - accuracy: 0.6124\n",
      "Epoch 677/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0085 - accuracy: 0.6117\n",
      "Epoch 678/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0083 - accuracy: 0.6135\n",
      "Epoch 679/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0079 - accuracy: 0.6122\n",
      "Epoch 680/5000\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 0.0090 - accuracy: 0.6108\n",
      "Epoch 681/5000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 0.0073 - accuracy: 0.6118\n",
      "Epoch 682/5000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0077 - accuracy: 0.6113\n",
      "Epoch 683/5000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0077 - accuracy: 0.6128\n",
      "Epoch 684/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0096 - accuracy: 0.6115\n",
      "Epoch 685/5000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.0077 - accuracy: 0.6111\n",
      "Epoch 686/5000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0107 - accuracy: 0.6124\n",
      "Epoch 687/5000\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0104 - accuracy: 0.6104\n",
      "Epoch 688/5000\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.0091 - accuracy: 0.6110\n",
      "Epoch 689/5000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 0.0090 - accuracy: 0.6103\n",
      "Epoch 690/5000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0085 - accuracy: 0.6112\n",
      "Epoch 691/5000\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0085 - accuracy: 0.6114\n",
      "Epoch 692/5000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.0078 - accuracy: 0.6131\n",
      "Epoch 693/5000\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0083 - accuracy: 0.6127\n",
      "Epoch 694/5000\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.0075 - accuracy: 0.6109\n",
      "Epoch 695/5000\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 0.0093 - accuracy: 0.6110\n",
      "Epoch 696/5000\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 0.0083 - accuracy: 0.6122\n",
      "Epoch 697/5000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.0094 - accuracy: 0.6115\n",
      "Epoch 698/5000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0080 - accuracy: 0.6112\n",
      "Epoch 699/5000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.0090 - accuracy: 0.6102\n",
      "Epoch 700/5000\n",
      "2/5 [===========>..................] - ETA: 0s - loss: 0.0110 - accuracy: 0.6208"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\Documents\\STUDY\\AutoEncoder\\VAE.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/Documents/STUDY/AutoEncoder/VAE.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m vae\u001b[39m.\u001b[39;49mfit(image_data, image_data, epochs\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae.fit(image_data, image_data, epochs=5000, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
